{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "embed resources: True\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project 2 Code\n",
    "Authors: Lily Geiser, Meredith Lou, Rich Pihlstrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "The datasets for our project are the following:\n",
    "\n",
    "1. [USA Tech Companies Stats](https://www.kaggle.com/datasets/lamiatabassum/top-50-us-tech-companies-2022-2023-dataset/data): data about the top 50 tech companies in the US for 2022-23. File: companies.csv\n",
    "2. [Per capita energy-related carbon dioxide emissions by state](https://www.eia.gov/environment/emissions/state/): data from the US Energy Information Administrations (EIA) about the per capita CO2 emissions per US state from 1970-2021. File: emissions.csv\n",
    "3. [NASDAQ-100 Stock Price Data](https://www.kaggle.com/datasets/kalilurrahman/nasdaq100-stock-price-data): data about stock prices of all NASDAQ-100 index stocks from 2010-21. File: stocks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "The code in this file cleans and process each of the three datasets. Important modifcations include converting columns to appropriate datatypes, melting columns for easier use, and imputing new columns based on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing libraries and output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def df_info(df):\n",
    "    print(f\"{'#'*3} COLUMN INFO {'#'*90}\")\n",
    "    print(df.info())\n",
    "    print(f\"{'#'*3} 5 RANDOM ROWS {'#'*88}\")\n",
    "    print(df.sample(5))\n",
    "    print(\"#\"*56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"companies\",\"emissions\",\"stocks\"]\n",
    "dfs = {}\n",
    "for file in files:\n",
    "    dfs[file] = pd.read_csv(f\"data/raw/{file}.csv\")\n",
    "    dfs[file] = dfs[file].rename(columns = {col:col.lower() for col in dfs[file].columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stocks\n",
    "\n",
    "The output below gives an overview of our stock data. First, we notice that columns like \"date\" are not formattes as datetime object. Second, we can see that the data is stored for small time increments. Other data that we have is by year, so we will aggregate this data to match. Finally, this data is a little bit hard to understand by itself, so we will impute some columns based on this data which we can use a bit more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### COLUMN INFO ##########################################################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271680 entries, 0 to 271679\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   date       271680 non-null  object \n",
      " 1   open       271680 non-null  float64\n",
      " 2   high       271680 non-null  float64\n",
      " 3   low        271680 non-null  float64\n",
      " 4   close      271680 non-null  float64\n",
      " 5   adj close  271680 non-null  float64\n",
      " 6   volume     271680 non-null  int64  \n",
      " 7   name       271680 non-null  object \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 16.6+ MB\n",
      "None\n",
      "### 5 RANDOM ROWS ########################################################################################\n",
      "              date       open       high        low      close  adj close  \\\n",
      "82733   2012-07-24  37.529999  37.639999  37.110001  37.520000  33.036900   \n",
      "135269  2016-07-01  32.639999  32.889999  32.470001  32.750000  28.593260   \n",
      "223976  2010-02-26  10.450000  10.490000  10.200000  10.200000  10.200000   \n",
      "16642   2017-08-29  74.160004  74.290001  73.820000  73.940002  64.622047   \n",
      "100860  2011-01-19  42.910000  43.040001  42.599998  42.820000  27.807745   \n",
      "\n",
      "          volume  name  \n",
      "82733     792500  CTAS  \n",
      "135269  17084600  INTC  \n",
      "223976    237400  SGEN  \n",
      "16642    1748900   AEP  \n",
      "100860   2792500   EXC  \n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "df_info(dfs[\"stocks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cast the date column as a datetime object. Using this new formatting, we can create a new column that just contains the year of the dateâ€”this will help us aggregate. Finally, we case-fold the name column following a preference to have all string columns be in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"stocks\"][\"date\"] = pd.to_datetime(dfs[\"stocks\"][\"date\"])\n",
    "dfs[\"stocks\"][\"year\"] = dfs[\"stocks\"][\"date\"].dt.year\n",
    "dfs[\"stocks\"][\"name\"] = dfs[\"stocks\"][\"name\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new \"year\" column, we aggregate the stock data by both \"name\" and \"year.\" This allows us to compute the yearly metrics of \"high,\" \"low,\" and \"change_in_close.\" These represent the highest price, lowest price, and change is closing price over the year, respectively. We replace our stock data with this imputed data, as it not only is aggregated in a more informative time granularity given the context of our data, but also is a bit easier to understand. NB: we changed the stock \"name\" to stock \"code.\" This allows clear distinction across all of our data for the full company name and its stock representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for tup, df in dfs[\"stocks\"].groupby([\"name\",\"year\"]):\n",
    "    rows.append([tup[0],tup[1],max(df[\"high\"]),min(df[\"low\"]),df[\"close\"].iloc[-1]-df[\"close\"].iloc[0]])\n",
    "dfs[\"stocks\"] = pd.DataFrame(rows, columns = [\"code\",\"year\",\"high\",\"low\",\"change_in_close\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see now that our columns are appropriate datatypes and that our stock data is redefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### COLUMN INFO ##########################################################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1120 entries, 0 to 1119\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   code             1120 non-null   object \n",
      " 1   year             1120 non-null   int64  \n",
      " 2   high             1120 non-null   float64\n",
      " 3   low              1120 non-null   float64\n",
      " 4   change_in_close  1120 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 43.9+ KB\n",
      "None\n",
      "### 5 RANDOM ROWS ########################################################################################\n",
      "      code  year        high         low  change_in_close\n",
      "36     adp  2010   41.413521   23.230904         3.028973\n",
      "196   biib  2014  361.929993  270.619995        59.120026\n",
      "1099   xel  2016   45.419998   35.189999         5.000000\n",
      "187   bidu  2017  274.970001  165.820007        65.910004\n",
      "377   dxcm  2011   16.910000    6.750000        -4.400000\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "df_info(dfs[\"stocks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies\n",
    "The output below gives an overview of our companny data. The most notable thing about this dataset is the clunky naming of columns. We will replace these with more usable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### COLUMN INFO ##########################################################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 10 columns):\n",
      " #   Column                                            Non-Null Count  Dtype  \n",
      "---  ------                                            --------------  -----  \n",
      " 0   company name                                      50 non-null     object \n",
      " 1   industry                                          50 non-null     object \n",
      " 2   sector                                            50 non-null     object \n",
      " 3   hq state                                          50 non-null     object \n",
      " 4   founding year                                     50 non-null     int64  \n",
      " 5   annual revenue 2022-2023 (usd in billions)        50 non-null     float64\n",
      " 6   market cap (usd in trillions)                     50 non-null     float64\n",
      " 7   stock name                                        50 non-null     object \n",
      " 8   annual income tax in 2022-2023 (usd in billions)  50 non-null     float64\n",
      " 9   employee size                                     50 non-null     int64  \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "### 5 RANDOM ROWS ########################################################################################\n",
      "         company name    industry                   sector    hq state  \\\n",
      "41     Snowflake Inc.  Technology     Software Application     Montana   \n",
      "22    ServiceNow Inc.  Technology     Software Application  California   \n",
      "6      Meta Platforms  Technology  Software Infrastructure  California   \n",
      "2   Alphabet (Google)  Technology  Software Infrastructure  California   \n",
      "29  Micron Technology  Technology           Semiconductors       Idaho   \n",
      "\n",
      "    founding year  annual revenue 2022-2023 (usd in billions)  \\\n",
      "41           2012                                        2.06   \n",
      "22           2004                                        7.24   \n",
      "6            2004                                      116.60   \n",
      "2            1998                                      282.83   \n",
      "29           1978                                       27.15   \n",
      "\n",
      "    market cap (usd in trillions) stock name  \\\n",
      "41                          0.046       SNOW   \n",
      "22                          0.090        NOW   \n",
      "6                           0.524       META   \n",
      "2                           1.350       GOOG   \n",
      "29                          0.064         MU   \n",
      "\n",
      "    annual income tax in 2022-2023 (usd in billions)  employee size  \n",
      "41                                             0.003           4991  \n",
      "22                                             0.074          20433  \n",
      "6                                              5.619          86482  \n",
      "2                                             11.356         190234  \n",
      "29                                             0.888          49000  \n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "df_info(dfs[\"companies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company name',\n",
       " 'industry',\n",
       " 'sector',\n",
       " 'hq state',\n",
       " 'founding year',\n",
       " 'annual revenue 2022-2023 (usd in billions)',\n",
       " 'market cap (usd in trillions)',\n",
       " 'stock name',\n",
       " 'annual income tax in 2022-2023 (usd in billions)',\n",
       " 'employee size']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfs[\"companies\"].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send all object columns to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(dfs[\"companies\"].columns):\n",
    "    if dfs[\"companies\"].dtypes[i] == object:\n",
    "        dfs[\"companies\"][col] = dfs[\"companies\"][col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the stock data, we rename the \"company name\" and \"stock name\" columns as \"name\" and \"code,\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple inc.', 'microsoft corporation', 'alphabet (google)', 'amazon', 'nvidia corporation', 'tesla', 'meta platforms', 'broadcom inc.', 'oracle corporation', 'cisco systems inc.', 'salesforce inc.', 'adobe inc.', 'texas instruments inc.', 'advanced micro devices (amd) inc.', 'qualcomm inc.', 'netflix', 'intel corporation', 'intuit inc.', 'ibm corporation', 'applied materials inc.', 'booking holdings', 'analog devices inc.', 'servicenow inc.', 'automatic data processing', 'paypal holdings inc.', 'airbnb', 'fiserv inc.', 'lam research corporation', 'uber technologies inc.', 'micron technology', 'equinix', 'activision blizzard', 'palo alto networks inc.', 'synopsys inc.', 'cadence design systems inc.', 'kla corporation', 'arista networks inc.', 'vmware inc.', 'workday inc.', 'fortinet inc.', 'block inc.', 'snowflake inc.', 'roper technologies', 'microchip technology inc.', 'autodesk inc.', 'globalfoundries', 'iqvia holdings', 'marvell technology inc.', 'dell technologies inc.', 'hp inc.']\n",
      "['aapl', 'msft', 'goog', 'amzn', 'nvda', 'tsla', 'meta', 'avgo', 'orcl', 'csco', 'crm', 'adbe', 'txn', 'amd', 'qcom', 'nflx', 'intc', 'intu', 'ibm', 'amat', 'bkng', 'adi', 'now', 'adp', 'pypl', 'abnb', 'fisv', 'lrcx', 'uber', 'mu', 'eqix', 'atvi', 'panw', 'snps', 'cdns', 'klac', 'anet', 'vmw', 'wday', 'ftnt', 'sq', 'snow', 'rop', 'mchp', 'adsk', 'gfs', 'iqv', 'mrvl', 'dell', 'hpq']\n"
     ]
    }
   ],
   "source": [
    "print(list(dfs[\"companies\"][\"company name\"].unique()))\n",
    "print(list(dfs[\"companies\"][\"stock name\"].unique()))\n",
    "\n",
    "dfs[\"companies\"] = dfs[\"companies\"].rename(columns = {\"company name\":\"name\",\n",
    "                                                      \"stock name\":\"code\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we rename six other columns for easier use with querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"companies\"] = dfs[\"companies\"].rename(columns = {\n",
    "    \"hq state\":\"state\",\n",
    "    \"founding year\":\"founded\",\n",
    "    \"annual revenue 2022-2023 (usd in billions)\":\"revenue_22_23_USD_e9\",\n",
    "    \"market cap (usd in trillions)\":\"market_cap_USD_e12\",\n",
    "    \"annual income tax in 2022-2023 (usd in billions)\":\"incomeTax_22_23_USD_e9\",\n",
    "    \"employee size\":\"emp_num\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our new company data has much more legible column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### COLUMN INFO ##########################################################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   name                    50 non-null     object \n",
      " 1   industry                50 non-null     object \n",
      " 2   sector                  50 non-null     object \n",
      " 3   state                   50 non-null     object \n",
      " 4   founded                 50 non-null     int64  \n",
      " 5   revenue_22_23_USD_e9    50 non-null     float64\n",
      " 6   market_cap_USD_e12      50 non-null     float64\n",
      " 7   code                    50 non-null     object \n",
      " 8   incomeTax_22_23_USD_e9  50 non-null     float64\n",
      " 9   emp_num                 50 non-null     int64  \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "### 5 RANDOM ROWS ########################################################################################\n",
      "                         name    industry                   sector  \\\n",
      "3                      amazon  technology     software application   \n",
      "17                intuit inc.  technology     software application   \n",
      "35            kla corporation  technology           semiconductors   \n",
      "43  microchip technology inc.  technology           semiconductors   \n",
      "6              meta platforms  technology  software infrastructure   \n",
      "\n",
      "         state  founded  revenue_22_23_USD_e9  market_cap_USD_e12  code  \\\n",
      "3   washington     1994                513.98               1.030  amzn   \n",
      "17  california     1983                 13.68               0.118  intu   \n",
      "35  california     1997                 10.48               0.053  klac   \n",
      "43     arizona     1989                  8.05               0.045  mchp   \n",
      "6   california     2004                116.60               0.524  meta   \n",
      "\n",
      "    incomeTax_22_23_USD_e9  emp_num  \n",
      "3                   -3.217  1541000  \n",
      "17                   0.476    17300  \n",
      "35                   0.167    14000  \n",
      "43                   0.197    21000  \n",
      "6                    5.619    86482  \n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "df_info(dfs[\"companies\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emissions\n",
    "The output below gives an overview of our per capita emissions data. This data is formatted such that each year has its own column. This is super annoying to use, so we will simply melt the columns appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>...</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>change_1970_2021_pct</th>\n",
       "      <th>change_1970_2021_abs</th>\n",
       "      <th>change_2020_2021_pct</th>\n",
       "      <th>change_2020_2021_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>25.2</td>\n",
       "      <td>26.3</td>\n",
       "      <td>26.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>-10.44%</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>3.42%</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>39.5</td>\n",
       "      <td>39.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>44.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>41.1</td>\n",
       "      <td>46.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.2</td>\n",
       "      <td>...</td>\n",
       "      <td>40.4</td>\n",
       "      <td>41.4</td>\n",
       "      <td>41.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>39.4</td>\n",
       "      <td>40.8</td>\n",
       "      <td>3.29%</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.43%</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Montana</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>27.2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>24.2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>25.29%</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.67%</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>29.7</td>\n",
       "      <td>28.2</td>\n",
       "      <td>29.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>28.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>27.8</td>\n",
       "      <td>...</td>\n",
       "      <td>23.4</td>\n",
       "      <td>22.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>-27.84%</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>9.70%</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>25.2</td>\n",
       "      <td>26.4</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>23.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.63%</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.40%</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  1970  1971  1972  1973  1974  1975  1976  1977  1978  ...  \\\n",
       "16     Kansas  22.7  23.5  24.9  25.2  25.3  25.2  26.3  26.7  29.0  ...   \n",
       "18  Louisiana  39.5  39.5  41.3  44.6  45.1  41.1  46.2  51.0  52.2  ...   \n",
       "26    Montana  20.6  20.9  21.8  23.4  22.5  22.5  25.7  26.8  27.2  ...   \n",
       "0     Alabama  29.7  28.2  29.7  30.6  30.0  29.3  28.9  29.5  27.8  ...   \n",
       "36   Oklahoma  21.6  21.5  22.3  22.2  22.6  22.5  24.4  25.2  26.4  ...   \n",
       "\n",
       "    2016  2017  2018  2019  2020  2021  change_1970_2021_pct  \\\n",
       "16  21.5  20.3  21.6  20.8  19.7  20.3               -10.44%   \n",
       "18  40.4  41.4  41.8  41.8  39.4  40.8                 3.29%   \n",
       "26  29.9  29.6  29.4  30.2  24.2  25.8                25.29%   \n",
       "0   23.4  22.3  23.0  21.6  19.6  21.5               -27.84%   \n",
       "36  24.5  23.8  25.0  23.1  21.3  22.0                 1.63%   \n",
       "\n",
       "    change_1970_2021_abs  change_2020_2021_pct  change_2020_2021_abs  \n",
       "16                  -2.4                 3.42%                   0.7  \n",
       "18                   1.3                 3.43%                   1.3  \n",
       "26                   5.2                 6.67%                   1.6  \n",
       "0                   -8.3                 9.70%                   1.9  \n",
       "36                   0.4                 3.40%                   0.7  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"emissions\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send all state names to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"emissions\"][\"state\"] = dfs[\"emissions\"][\"state\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final row of the data gives the average across all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>...</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>change_1970_2021_pct</th>\n",
       "      <th>change_1970_2021_abs</th>\n",
       "      <th>change_2020_2021_pct</th>\n",
       "      <th>change_2020_2021_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>-21.02%</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>6.51%</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>wyoming</td>\n",
       "      <td>55.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>62.4</td>\n",
       "      <td>66.9</td>\n",
       "      <td>65.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>77.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>85.7</td>\n",
       "      <td>...</td>\n",
       "      <td>104.7</td>\n",
       "      <td>108.3</td>\n",
       "      <td>110.3</td>\n",
       "      <td>101.9</td>\n",
       "      <td>96.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>69.38%</td>\n",
       "      <td>38.6</td>\n",
       "      <td>-2.02%</td>\n",
       "      <td>-1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>average all states</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-28.67%</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>6.72%</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 state  1970  1971  1972  1973  1974  1975  1976  1977  1978  \\\n",
       "49           wisconsin  19.9  19.0  18.7  18.9  18.1  17.6  18.3  18.8  19.1   \n",
       "50             wyoming  55.7  55.3  62.4  66.9  65.3  66.3  77.7  87.9  85.7   \n",
       "51  average all states  20.7  20.7  21.5  22.2  21.2  20.5  21.5  21.9  21.9   \n",
       "\n",
       "    ...   2016   2017   2018   2019  2020  2021  change_1970_2021_pct  \\\n",
       "49  ...   16.6   17.0   17.4   16.3  14.8  15.7               -21.02%   \n",
       "50  ...  104.7  108.3  110.3  101.9  96.2  94.3                69.38%   \n",
       "51  ...   16.0   15.8   16.2   15.7  13.9  14.8               -28.67%   \n",
       "\n",
       "    change_1970_2021_abs  change_2020_2021_pct  change_2020_2021_abs  \n",
       "49                  -4.2                 6.51%                   1.0  \n",
       "50                  38.6                -2.02%                  -1.9  \n",
       "51                  -5.9                 6.72%                   0.9  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"emissions\"].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very useful, as we will probably be merging on the state. As such, we can just drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>...</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>change_1970_2021_pct</th>\n",
       "      <th>change_1970_2021_abs</th>\n",
       "      <th>change_2020_2021_pct</th>\n",
       "      <th>change_2020_2021_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>west virginia</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>53.1</td>\n",
       "      <td>55.4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>...</td>\n",
       "      <td>51.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>49.4</td>\n",
       "      <td>47.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>12.61%</td>\n",
       "      <td>5.5</td>\n",
       "      <td>15.25%</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>-21.02%</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>6.51%</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>wyoming</td>\n",
       "      <td>55.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>62.4</td>\n",
       "      <td>66.9</td>\n",
       "      <td>65.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>77.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>85.7</td>\n",
       "      <td>...</td>\n",
       "      <td>104.7</td>\n",
       "      <td>108.3</td>\n",
       "      <td>110.3</td>\n",
       "      <td>101.9</td>\n",
       "      <td>96.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>69.38%</td>\n",
       "      <td>38.6</td>\n",
       "      <td>-2.02%</td>\n",
       "      <td>-1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  1970  1971  1972  1973  1974  1975  1976  1977  1978  ...  \\\n",
       "48  west virginia  44.0  44.0  49.5  54.0  55.3  53.1  55.4  54.0  50.3  ...   \n",
       "49      wisconsin  19.9  19.0  18.7  18.9  18.1  17.6  18.3  18.8  19.1  ...   \n",
       "50        wyoming  55.7  55.3  62.4  66.9  65.3  66.3  77.7  87.9  85.7  ...   \n",
       "\n",
       "     2016   2017   2018   2019  2020  2021  change_1970_2021_pct  \\\n",
       "48   51.6   49.9   49.4   47.6  43.0  49.5                12.61%   \n",
       "49   16.6   17.0   17.4   16.3  14.8  15.7               -21.02%   \n",
       "50  104.7  108.3  110.3  101.9  96.2  94.3                69.38%   \n",
       "\n",
       "    change_1970_2021_abs  change_2020_2021_pct  change_2020_2021_abs  \n",
       "48                   5.5                15.25%                   6.5  \n",
       "49                  -4.2                 6.51%                   1.0  \n",
       "50                  38.6                -2.02%                  -1.9  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"emissions\"] = dfs[\"emissions\"].iloc[:-1]\n",
    "dfs[\"emissions\"].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We melt the columns here. Additionally, we are not super interested in the columns about percent-change over certain years, so we can also drop those columns. When we melt the data, we leave the \"state\" column alone, send the column headers (each year) to the \"year\" column, and the corresponding values per State-Year to the \"emissions_per_cap\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"emissions\"] = dfs[\"emissions\"][dfs[\"emissions\"].columns[:-4]].melt(id_vars = \"state\",\n",
    "                                                                      var_name = \"year\",\n",
    "                                                                      value_name = \"emissions_per_cap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have substantially reduced the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### COLUMN INFO ##########################################################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2652 entries, 0 to 2651\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   state              2652 non-null   object \n",
      " 1   year               2652 non-null   object \n",
      " 2   emissions_per_cap  2652 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 62.3+ KB\n",
      "None\n",
      "### 5 RANDOM ROWS ########################################################################################\n",
      "                     state  year  emissions_per_cap\n",
      "518   district of columbia  1980                8.2\n",
      "1419             tennessee  1997               22.3\n",
      "370               illinois  1977               22.5\n",
      "1472                  utah  1998               29.3\n",
      "1810              missouri  2005               25.0\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "df_info(dfs[\"emissions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then simply output each cleaned file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    dfs[file].to_csv(f\"data/cleaned/{file}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
